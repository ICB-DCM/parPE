# https://github.com/marketplace/actions/publish-docker
name: Shippable workflow
on: [push]
jobs:
  container:
    runs-on: ubuntu-latest
    container: dweindl/parpeci:892872
    name: Ship
    steps:
    - uses: actions/checkout@master

    - run: echo "::set-env name=PARPE_BASE::$(pwd)"
    - run: echo "::set-env name=PARPE_BUILD::${PARPE_BASE}/build"
    - run: echo "::set-env name=AMICI_PATH::${PARPE_BASE}/deps/AMICI/"

    - name: info
      run: lsb_release -a && printenv

      # Build dependencies

    - name: Install AMICI deps
      run: |
        cd $AMICI_PATH \
          && scripts/buildSuiteSparse.sh \
          && scripts/buildSundials.sh \
          && scripts/buildCpputest.sh #&& scripts/buildAmici.sh

    - name: Install AMICI
      run: |
        set -x && CPPUTEST_BUILD_DIR=${AMICI_PATH}/ThirdParty/cpputest-master/build/ \
          && cmake \
            -DCMAKE_BUILD_TYPE=Debug \
            -DENABLE_PYTHON=ON \
            -DBUILD_TESTS=OFF \
            -DCppUTest_DIR=${CPPUTEST_BUILD_DIR} \
            -S ${AMICI_PATH} -B ${AMICI_PATH}/build \
          && make -j12

      #- cd $PARPE_BASE/ThirdParty && ./installCeres.sh

    - name: Install google test
      run: ThirdParty/installGoogleTest.sh

    - name: build parPE
      run: |
        pip install -r ${PARPE_BASE}/python/requirements.txt \
          && ./buildShippable.sh

    - name: run tests
      run: cd ${PARPE_BUILD} && CTEST_OUTPUT_ON_FAILURE=1 make test

    - name: valgrind
      run: |
        cd ${PARPE_BUILD} \
          && CTEST_OUTPUT_ON_FAILURE=1 make ExperimentalMemCheck; \
          cat Testing/Temporary/MemoryChecker.*.log

    - name: coverage report
      run: |
        cd ${PARPE_BUILD} \
          && CTEST_OUTPUT_ON_FAILURE=1 make parpe_coverage_cobertura

    - run: |
        mkdir -p $PARPE_BASE/shippable/codecoverage \
          && cp $PARPE_BASE/build/parpe_coverage_cobertura.xml \
            $PARPE_BASE/shippable/codecoverage


    - name: PEtab test suite --- requirements
      run: |
        $PARPE_BASE/misc/run_in_venv.sh $PARPE_BASE/build/venv pip3 install pytest-xdist

    - name: PEtab test suite --- repository
      run: |
        cd $PARPE_BASE/ && git clone --depth 1 https://github.com/PEtab-dev/petab_test_suite.git && $PARPE_BASE/misc/run_in_venv.sh $PARPE_BASE/build/venv pip3 install -e petab_test_suite

    - name: PEtab test suite --- tests
      run: |
        $PARPE_BASE/misc/run_in_venv.sh $PARPE_BASE/build/venv pytest -v -n 2 $PARPE_BASE/tests/petab-test-suite


    - name: Benchmark models --- requirements
      run: |
        sudo apt install bc \
          && $PARPE_BASE/misc/run_in_venv.sh $PARPE_BASE/build/venv \
              pip3 install shyaml

    - name: Benchmark models --- repository
      env:
        BM_REPO_URL: https://github.com/Benchmarking-Initiative/Benchmark-Models-PEtab.git
      run: |
        cd $PARPE_BASE/benchmark_collection \
          && git clone --depth 1 $BM_REPO_URL

    - name: Benchmark models --- tests
      run: AMICI_PARALLEL_COMPILE=4 BENCHMARK_COLLECTION="$(pwd)/Benchmark-Models-PEtab/Benchmark-Models/" $PARPE_BASE/misc/run_in_venv.sh $PARPE_BASE/build/venv ./all.sh
